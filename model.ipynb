{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still work in progress. Will be constructing a graph neural network to input the data and find the L2 orbit loss. Afterward I will also try a GAN to do the same task and compare their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import datetime\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(x, scope, num_h, n_x):\n",
    "    \"\"\"\n",
    "    standard affine layer\n",
    "    scope = name tf variable scope\n",
    "    num_h = number of hidden units\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        w = tf.get_variable('w', [n_x, num_h], initializer=tf.random_normal_initializer(stddev=0.04))\n",
    "        b = tf.get_variable('b', [num_h], initializer=tf.constant_initializer(0))\n",
    "        return tf.matmul(x, w)+b\n",
    "\n",
    "def noise(X, std=1):\n",
    "    \"\"\"\n",
    "    adds gaussian noise with unit variance\n",
    "    \"\"\"\n",
    "    noise = tf.random_normal(shape=tf.shape(X), mean=0.0, stddev=std, dtype=tf.float32) \n",
    "    return(input_layer + noise)\n",
    "    \n",
    "def conv(x, scope, filter_h,filter_w, n_kernel, stride_h=1,stride_w=1, padding='SAME'):\n",
    "    \"\"\"\n",
    "    1d convolutions over multiple 1d images\n",
    "    scope        = name tf variable scope\n",
    "    filter_width = receptive field of kernel\n",
    "    n_kernel     = # of kernels\n",
    "    stride       = locations\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "        n_x = x.get_shape().as_list()[-1]\n",
    "        w = tf.get_variable('w',\n",
    "                            [filter_h, filter_w, n_x, n_kernel],\n",
    "                            initializer=tf.random_normal_initializer(stddev=0.04))\n",
    "        b = tf.get_variable('b', [n_kernel], initializer=tf.constant_initializer(0))\n",
    "        return tf.nn.convolution(x, w, padding=padding, strides=[stride_h, stride_w])+b    \n",
    "\n",
    "\n",
    "def maxpool(X, scope, filter_h,filter_w, stride_h,stride_w, padding='VALID'):\n",
    "    \"\"\"\n",
    "    maxpool operation over multiple 1d images\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE) as scope:\n",
    "        pool = tf.nn.max_pool(X, \n",
    "                            ksize=[1, filter_h, filter_w, 1], \n",
    "                            strides=[1, stride_h, stride_w, 1],\n",
    "                            padding=padding)\n",
    "    return pool    \n",
    "    \n",
    "def upsample(X, ratio=2):\n",
    "    \"\"\"\n",
    "    Takes a 4D image tensor and increases spatial resolution by replicating values\n",
    "    \"\"\"\n",
    "    n_h, n_w = X.get_shape().as_list()[1:3]\n",
    "    return tf.image.resize_nearest_neighbor(X, [n_h*ratio, n_w*ratio])\n",
    "    \n",
    "    \n",
    "def convOneDImages(X, reuse=False):\n",
    "    \"\"\"\n",
    "    Makes convolutions over 1D images and takes their averages\n",
    "    for given object. Currently trying an approach similar to GNN.\n",
    "    \"\"\"\n",
    "    n_batch = tf.shape(X)[0]\n",
    "    model_n_img_per_obj = X.get_shape().as_list()[1]\n",
    "    model_n_img_per_obj = X\n",
    "    with tf.variable_scope('convOneDImages', reuse=reuse):\n",
    "        h = tf.nn.leaky_relu(conv(X, 'conv0',1,5,32,1,2), 0.1)    #32x32\n",
    "        h = tf.nn.leaky_relu(conv(h, 'conv1', 1,3,64,1,1), 0.1)   #32x64\n",
    "        h = maxpool(h,'pool1', 1,2,1,2,'VALID')                        #16x64\n",
    "        h = tf.nn.leaky_relu(conv(h, 'conv2', 1,3,128,1,1), 0.1)  #16x128\n",
    "        h = maxpool(h,'pool2', 1,2,1,2,'VALID')                        #8x128\n",
    "        h = tf.nn.leaky_relu(conv(h, 'conv3', 1,3,256,1,1), 0.1)  #8x256\n",
    "        h = maxpool(h,'pool3', 1,2,1,2,'VALID')                        #4x256\n",
    "        h = tf.reshape(h, [50* 32, -1])                   # batchsize 50, n_img=32\n",
    "        \n",
    "        h = tf.nn.leaky_relu(dense(h, 'fc_0', 512,4*256), 0.1)\n",
    "        h = tf.nn.leaky_relu(dense(h, 'fc_1', 512,512), 0.1)\n",
    "        h = tf.reshape(h, [50, 32, 512]) \n",
    "\n",
    "        h = tf.reduce_mean(h, 1)\n",
    "        return h\n",
    "\n",
    "\n",
    "def gen2DObj(X, reuse=False):\n",
    "    \"\"\"\n",
    "    Takes encoding produced by the 1D images as input and\n",
    "    generates a 2D image of the object\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('2D_object_generator', reuse=reuse):\n",
    "        h = tf.nn.leaky_relu(dense(X, 'hz', num_h=6*6*32,n_x=512), 0.1)\n",
    "        h = tf.nn.leaky_relu(dense(h, 'hz1', num_h=6*6*128,n_x=6*6*32), 0.1)\n",
    "        h = tf.reshape(h, [50, 6, 6, 128]) \n",
    "        h = upsample(h)                                          #12x12x128\n",
    "        h = tf.nn.leaky_relu(conv(h, 'h1', 3,3, n_kernel=64), 0.1)    #12x12x64\n",
    "        h = upsample(h)                                          #24x24x64\n",
    "        h = tf.nn.leaky_relu(conv(h, 'h2', 3,3, n_kernel=32), 0.1)    #24x24x32\n",
    "        h = upsample(h)                                          #48x48x32\n",
    "        h = tf.nn.leaky_relu(conv(h, 'h3', 3,3, n_kernel=16), 0.1)    #48x48x16\n",
    "        h = conv(h, 'hx', 1,1,1)\n",
    "        return h    \n",
    "    \n",
    "\n",
    "class objGenNetwork(object):\n",
    "    \"\"\"\n",
    "    not finished.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 imgDim = 64,\n",
    "                 o_imgDim = 48,\n",
    "                 model_n_img_per_obj = 32,\n",
    "                 noise = 0.5,\n",
    "                 minibatchSize = 50,\n",
    "                 testSampleSize = 1000,\n",
    "                 lr = 0.001,\n",
    "                 nProcess_dataprep = 4,\n",
    "                 training = True,\n",
    "                 shift_n = 8\n",
    "                ):\n",
    "        \n",
    "        self.imgDim = imgDim\n",
    "        self.o_imgDim = o_imgDim\n",
    "        self.model_n_img_per_obj = model_n_img_per_obj\n",
    "        self.noise = noise\n",
    "        self.minibatchSize = minibatchSize\n",
    "        self.testSampleSize = testSampleSize\n",
    "        self.lr = lr\n",
    "        self.nProcess_dataprep = nProcess_dataprep\n",
    "        self.training = training\n",
    "        self.shift_n = shift_n\n",
    "        self.skip_step = 1\n",
    "        \n",
    "        self.gstep = tf.Variable(0, \n",
    "                                 dtype=tf.int32, \n",
    "                                 trainable=False,\n",
    "                                 name='global_step')\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "\n",
    "    def data_generator(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Reads chunks of data starting for the i'th iteration.\n",
    "        Prepares train_x, test_x, train_y, test_y \n",
    "        \"\"\"\n",
    "        nProcess_dataprep=self.nProcess_dataprep\n",
    "        minibatchSize = self.minibatchSize\n",
    "        testSampleSize = self.testSampleSize\n",
    "        imgDim = self.imgDim\n",
    "        o_imgDim = self.o_imgDim\n",
    "        noise = self.noise\n",
    "        shift_n = self.shift_n\n",
    "        model_n_img_per_obj=self.model_n_img_per_obj\n",
    "        trainingBatch=True\n",
    "        \n",
    "        batches = minibatchSize if trainingBatch else testSampleSize\n",
    "        \n",
    "        pool = mp.Pool(processes=nProcess_dataprep)\n",
    "        results = pool.map(gen_rand_poly_images,[model_n_img_per_obj] * batches )\n",
    "        pool.close(); pool.join()\n",
    "        \n",
    "        batch_x = np.expand_dims(np.array([k[1] for k in results],\n",
    "                                          dtype='float32'),\n",
    "                                 axis=3)\n",
    "        batch_y = np.expand_dims(np.array([k[2] for k in results],\n",
    "                                          dtype='float32'),\n",
    "                                 axis=4)\n",
    "        \n",
    "        # add gaussian noise\n",
    "        if(noise > 0):\n",
    "            batch_x = batch_x + np.random.normal(0,1,batch_x.shape)\n",
    "\n",
    "        if trainingBatch:\n",
    "            self.train_x_new = batch_x\n",
    "            self.train_y_new = batch_y\n",
    "        else:\n",
    "            self.new_test_x = batch_x\n",
    "            self.new_test_y = batch_y\n",
    "        \n",
    "        \n",
    "    def inference(self):\n",
    "        h = convOneDImages(self.x_ph)\n",
    "        self.logits = gen2DObj(h)\n",
    "\n",
    "        \n",
    "    def loss(self):\n",
    "        \"\"\"\n",
    "        define loss function\n",
    "        use softmax cross entropy with logits as the loss function\n",
    "        compute mean cross entropy, softmax is applied internally\n",
    "        \"\"\"\n",
    "        # \n",
    "        with tf.name_scope('loss'):\n",
    "            tiled_logits = tf.tile(tf.expand_dims(self.logits, 1),[1,360,1,1,1])\n",
    "            entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.y_ph, logits=tiled_logits)\n",
    "            entropy = tf.reduce_min(entropy,axis = 1)\n",
    "            self.loss = tf.reduce_mean(entropy, name='loss')\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        define optimization op\n",
    "        \"\"\"\n",
    "        self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.loss, \n",
    "                                                global_step=self.gstep)\n",
    "\n",
    "    def eval_graph(self):\n",
    "        \"\"\"\n",
    "        For each prediction, takes the most accurate rotation\n",
    "        of the true object as reference and calculates the average\n",
    "        accuracy of the occupancy grid of the object\n",
    "        \"\"\"\n",
    "        with tf.name_scope('predict'):           \n",
    "            preds = tf.nn.sigmoid(self.logits)\n",
    "            tiled_preds = tf.tile(tf.expand_dims(preds, 1),[1,360,1,1, 1])\n",
    "            correct_preds = tf.equal(tf.round(tiled_preds), self.y_ph)\n",
    "            accuracy_best = tf.reduce_max(tf.cast(correct_preds, tf.float32), axis = 1)\n",
    "            self.accuracy = tf.reduce_mean(accuracy_best)\n",
    "        \n",
    "        \n",
    "    def eval_once(self, sess, writer, epoch, step):\n",
    "        accuracy_batch, summaries = sess.run([self.accuracy,\n",
    "                                              self.summary_op],\n",
    "                                             feed_dict={self.x_ph: self.train_x_new,\n",
    "                                                        self.y_ph: self.train_y_new})\n",
    "        writer.add_summary(summaries, global_step=step)\n",
    "        print('Accuracy at epoch {0}: {1} '.format(epoch,accuracy_batch))\n",
    "        \n",
    "\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Summary for TensorBoard\n",
    "        \"\"\"\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            tf.summary.scalar('accuracy', self.accuracy)\n",
    "            tf.summary.histogram('histogram loss', self.loss)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Build the computation graph\n",
    "        \"\"\"\n",
    "        self.x_ph = tf.placeholder(tf.float32, [None, 32,64,1]) \n",
    "        self.y_ph = tf.placeholder(tf.float32, [None, 360,48,48,1])\n",
    "        self.data_generator()\n",
    "        self.inference()\n",
    "        self.loss()\n",
    "        self.optimize()\n",
    "        self.eval_graph()\n",
    "        self.summary()\n",
    "    \n",
    "    def train_one_epoch(self, sess, saver, writer, epoch, step):\n",
    "#        start_time = time.time()\n",
    "        self.training = True\n",
    "        _, l, summaries = sess.run([self.opt, \n",
    "                                    self.loss,\n",
    "                                    self.summary_op],\n",
    "                                   feed_dict={self.x_ph: self.train_x_new,\n",
    "                                              self.y_ph: self.train_y_new})\n",
    "        writer.add_summary(summaries, global_step=step)\n",
    "        if (step + 1) % self.skip_step == 0:\n",
    "            print('Loss at step {0}: {1}'.format(step, l))\n",
    "        step += 1\n",
    "        saver.save(sess, 'checkpoints/cryoem/cryoem_v1', step)\n",
    "#        print('Average loss at epoch {0}: {1}'.format(epoch, l))\n",
    "#        print('Took: {0} seconds'.format(time.time() - start_time))\n",
    "        return step\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        \"\"\"\n",
    "        The train function alternates between training one epoch and evaluating\n",
    "        \"\"\"\n",
    "        safe_mkdir('checkpoints')\n",
    "        safe_mkdir('checkpoints/cryoem')\n",
    "        writer = tf.summary.FileWriter('./graphs/cryoem_v1', tf.get_default_graph())\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver = tf.train.Saver()\n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/cryoem/cryoem_v1'))\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            step = self.gstep.eval()\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                self.train_x = self.train_x_new\n",
    "                self.train_y = self.train_y_new\n",
    "\n",
    "                pool = ThreadPool(processes=1)\n",
    "                async_result = pool.apply_async(self.data_generator,())\n",
    "                step = self.train_one_epoch(sess, saver, writer, epoch, step)\n",
    "                pool.close()\n",
    "                pool.join()\n",
    "                self.eval_once(sess, writer, epoch, step)\n",
    "        writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name histogram loss is illegal; using histogram_loss instead.\n"
     ]
    }
   ],
   "source": [
    "model = objGenNetwork()\n",
    "model.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0: 0.6927354335784912\n",
      "Accuracy at epoch 0: 0.9044097065925598 \n",
      "Loss at step 1: 0.679400622844696\n",
      "Accuracy at epoch 1: 0.8859201669692993 \n",
      "Loss at step 2: 0.6101904511451721\n",
      "Accuracy at epoch 2: 0.8989322781562805 \n",
      "Loss at step 3: 0.39158859848976135\n",
      "Accuracy at epoch 3: 0.9072916507720947 \n",
      "Loss at step 4: 0.2797037661075592\n",
      "Accuracy at epoch 4: 0.903967022895813 \n",
      "Loss at step 5: 0.24782182276248932\n",
      "Accuracy at epoch 5: 0.9213975667953491 \n",
      "Loss at step 6: 0.17488929629325867\n",
      "Accuracy at epoch 6: 0.93729168176651 \n",
      "Loss at step 7: 0.1565966159105301\n",
      "Accuracy at epoch 7: 0.9616666436195374 \n",
      "Loss at step 8: 0.15781818330287933\n",
      "Accuracy at epoch 8: 0.9823524355888367 \n",
      "Loss at step 9: 0.1516440361738205\n",
      "Accuracy at epoch 9: 0.9825607538223267 \n",
      "Loss at step 10: 0.1366826891899109\n",
      "Accuracy at epoch 10: 0.9806163311004639 \n",
      "Loss at step 11: 0.12341755628585815\n",
      "Accuracy at epoch 11: 0.9817361235618591 \n",
      "Loss at step 12: 0.11431533843278885\n",
      "Accuracy at epoch 12: 0.9913802146911621 \n",
      "Loss at step 13: 0.07835543900728226\n",
      "Accuracy at epoch 13: 0.9914323091506958 \n",
      "Loss at step 14: 0.06249538064002991\n",
      "Accuracy at epoch 14: 0.9893836975097656 \n",
      "Loss at step 15: 0.0545024573802948\n",
      "Accuracy at epoch 15: 0.9983159899711609 \n",
      "Loss at step 16: 0.020315641537308693\n",
      "Accuracy at epoch 16: 0.9995225667953491 \n",
      "Loss at step 17: 0.010055198334157467\n",
      "Accuracy at epoch 17: 0.9997656345367432 \n",
      "Loss at step 18: 0.007143028080463409\n",
      "Accuracy at epoch 18: 0.9997222423553467 \n",
      "Loss at step 19: 0.0071395449340343475\n",
      "Accuracy at epoch 19: 1.0 \n",
      "Loss at step 20: 0.004692068323493004\n",
      "Accuracy at epoch 20: 0.9999826550483704 \n",
      "Loss at step 21: 0.0031651814933866262\n",
      "Accuracy at epoch 21: 1.0 \n"
     ]
    }
   ],
   "source": [
    "model.train(n_epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
